{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from torchtext import data\n",
    "from transformers import T5Tokenizer, T5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Hello', '▁world', '▁how', '▁are', '▁you', '?']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('Hello world how are you?')\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8774, 296, 149, 33, 25, 58]\n"
     ]
    }
   ],
   "source": [
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> </s> <pad> <unk>\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.pad_token\n",
    "eos_token = tokenizer.eos_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0 2\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['t5-small']\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "TRG = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('src', SRC), ('trg', TRG)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.TabularDataset.splits(\n",
    "                path = '',\n",
    "                train = 'marco2.csv',\n",
    "                format = 'csv',\n",
    "                fields = fields,\n",
    "                skip_header = True)\n",
    "\n",
    "train_data , valid_data = train_data[0].split(split_ratio=0.98,\n",
    "                                             random_state = random.seed(4321))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88200\n",
      "1800\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data.examples))\n",
    "print(len(valid_data.examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': [2625, 3, 10, 8, 3334, 1085, 1104, 1080, 21, 3, 4059, 109, 4411, 6, 3, 7, 75, 19, 4848, 2712, 5, 48, 19, 8, 792, 13, 538, 6, 5435, 11, 690, 1085, 1104, 1917, 5, 8, 3414, 443, 12057, 9, 538, 1085, 1104, 1080, 19, 1083, 3, 6370, 5, 8, 3, 1152, 1050, 1306, 5435, 1085, 1104, 1080, 19, 3, 6932, 5, 3, 4059, 109, 4411, 1085, 1104, 1080, 19, 3, 4704, 5, 11417, 3, 10, 125, 19, 8, 1085, 1104, 1080, 16, 3, 4059, 109, 4411, 3, 7, 75], 'trg': [4848, 2712]}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁context', '▁', ':', '▁the', '▁combined', '▁sales', '▁tax', '▁rate', '▁for', '▁', 'char', 'le', 'ston', ',', '▁', 's', 'c', '▁is', '▁8.', '5%', '.', '▁this', '▁is', '▁the', '▁total', '▁of', '▁state', ',', '▁county', '▁and', '▁city', '▁sales', '▁tax', '▁rates', '.', '▁the', '▁south', '▁car', 'olin', 'a', '▁state', '▁sales', '▁tax', '▁rate', '▁is', '▁currently', '▁', '6%', '.', '▁the', '▁', 'ber', 'ke', 'ley', '▁county', '▁sales', '▁tax', '▁rate', '▁is', '▁', '0%', '.', '▁', 'char', 'le', 'ston', '▁sales', '▁tax', '▁rate', '▁is', '▁', '1%', '.', '▁query', '▁', ':', '▁what', '▁is', '▁the', '▁sales', '▁tax', '▁rate', '▁in', '▁', 'char', 'le', 'ston', '▁', 's', 'c']\n",
      "['▁8.', '5%']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[10000])['src'])\n",
    "\n",
    "print(tokens)\n",
    "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[10000])['trg'])\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "train_iterator, valid_iterator = BucketIterator.splits(\n",
    "                                (train_data, valid_data), \n",
    "                                batch_size = BATCH_SIZE,\n",
    "                                device = device,\n",
    "                                sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.t5 = t5 = T5Model.from_pretrained('t5-small')\n",
    "        \n",
    "        self.out = nn.Linear(t5.config.to_dict()['d_model'], t5.config.to_dict()['vocab_size'])\n",
    "                \n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        embedded = self.t5(input_ids=src, decoder_input_ids=trg)\n",
    "        \n",
    "        output = self.out(embedded[0])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = T5Network().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 76,988,544 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0004\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 4\n",
    "CLIP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1\tTRAIN LOSS : 1.96\tVALID LOSS : 0.83\tTIME : 1413.11\n",
      "\n",
      "EPOCH : 2\tTRAIN LOSS : 0.73\tVALID LOSS : 0.72\tTIME : 1442.93\n",
      "\n",
      "EPOCH : 3\tTRAIN LOSS : 0.56\tVALID LOSS : 0.71\tTIME : 1443.43\n",
      "\n",
      "EPOCH : 4\tTRAIN LOSS : 0.47\tVALID LOSS : 0.74\tTIME : 2776.08\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start = time.time()\n",
    "    # TRAIN \n",
    "    #########################################################################\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg[:,:-1])\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    train_loss = epoch_loss / len(train_iterator)\n",
    "    #########################################################################\n",
    "    \n",
    "    # VALID\n",
    "    #########################################################################\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(valid_iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg[:,:-1])\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    valid_loss = epoch_loss / len(valid_iterator)\n",
    "    #########################################################################\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"EPOCH : {epoch+1}\\tTRAIN LOSS : {train_loss:.2f}\\tVALID LOSS : {valid_loss:.2f}\\tTIME : {end-start:.2f}\\n\")\n",
    "    torch.save(model.state_dict(), f'saved_models/marco_model_{epoch+1}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "    model.eval()\n",
    "\n",
    "    src_indexes = [init_token_idx] + sentence + [eos_token_idx]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    trg_indexes = [init_token_idx]\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, trg_tensor)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == eos_token_idx:\n",
    "            break\n",
    "            \n",
    "    return trg_indexes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC : ▁context ▁ : ▁add ▁ a ▁photo ▁to ▁this ▁gallery . ▁1 ▁them y s cir a ▁was ▁shown ▁on ▁the ▁television ▁movie ▁wonder ▁woman ▁ starring ▁actress ▁ca th y ▁le e ▁ cro s by . ▁the ▁scene ▁was ▁very ▁brief ▁and ▁no ▁details ▁about ▁the ▁island ▁were ▁disclosed . ▁ titled ▁paradise ▁island , ▁it ▁was ▁shown ▁in ▁the ▁ ly nd a ▁carte r ▁television ▁series ▁wonder ▁woman ▁throughout ▁several ▁episodes . ▁query ▁ : ▁what ▁island ▁was ▁used ▁for ▁them y s cir a ▁in ▁wonder ▁woman\n",
      "TRG : ▁paradise ▁island\n",
      "PREDICTED : ▁paradise ▁island </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁nutrition ▁summary : ▁there ▁are ▁130 ▁calories ▁in ▁ a ▁1 ▁cup ▁serving ▁of ▁healthy ▁choice ▁italian ▁style ▁wedding ▁soup ▁( m eat ball s ▁ & ▁spinach ▁in ▁chicken ▁broth ▁with ▁ a cini ▁de ▁pe pe ▁pasta ). ▁ calorie ▁breakdown : ▁1 6% ▁fat , ▁5 5% ▁carb s , ▁2 9% ▁protein . ▁query ▁ : ▁calories ▁in ▁wedding ▁soup ▁broth\n",
      "TRG : ▁130 ▁calories\n",
      "PREDICTED : ▁130 ▁calories ▁in ▁ a ▁1 ▁cup </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁city ▁had ▁ ... ▁planned ▁to ▁tear ▁it ▁down ▁( part ▁of ▁the ▁original ▁contest ▁rules ▁for ▁designing ▁ a ▁tower ▁was ▁that ▁it ▁could ▁be ▁easily ▁de mol ished ) ▁but ▁as ▁the ▁tower ▁proved ▁valuable ▁for ▁communication ▁purposes , ▁it ▁was ▁allowed ▁to ▁remain ▁after ▁the ▁expir ation ▁of ▁the ▁permit . ▁query ▁ : ▁was ▁the ▁ e i ffel ▁tower ▁supposed ▁to ▁be ▁destroyed\n",
      "TRG : ▁no\n",
      "PREDICTED : ▁yes </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁genetic s ▁is ▁the ▁study ▁of ▁genes , ▁genetic ▁variation , ▁and ▁here d ity ▁in ▁living ▁organism s . ▁it ▁is ▁generally ▁considered ▁ a ▁field ▁of ▁biology , ▁but ▁intersect s ▁frequently ▁with ▁many ▁other ▁life ▁sciences ▁and ▁is ▁strongly ▁linked ▁with ▁the ▁study ▁of ▁information ▁systems . ▁query ▁ : ▁what ▁do ▁genetic s ▁mean ?\n",
      "TRG : ▁the ▁study ▁of ▁genes , ▁genetic ▁variation , ▁and ▁here d ity ▁in ▁living ▁organism s .\n",
      "PREDICTED : ▁genetic ▁variation , ▁and ▁here d ity ▁in ▁living ▁organism s . </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁major ▁ethnic ▁groups ▁in ▁central ▁ asia . ▁the ▁and r o nov o ▁culture ▁shows ▁evidence ▁of ▁ a ▁very ▁early ▁history ▁( late ▁bronze ▁age ) ▁of ▁the ▁in d o - i r a nian ▁speaking ▁people s ▁in ▁central ▁ asia . ▁ tur k ic ▁people ▁came ▁to ▁these ▁areas ▁much ▁later , ▁during ▁the ▁middle ▁age . ▁ethnic ally , ▁central ▁ asia ▁occupie s ▁ a ▁kind ▁of ▁bridge ▁between ▁the ▁ tur k ic ▁and ▁per sian ▁world s . ▁while ▁various ▁ethnic ▁groups ▁historically ▁ occupied ▁different ▁economic ▁niche s , ▁they ▁were ▁all ▁native to ▁the ▁land . ▁query ▁ : ▁what ▁ethnic ▁groups ▁live ▁ asia\n",
      "TRG : ▁in d o - i r a nian , ▁ tur k ic ▁and ▁arab s\n",
      "PREDICTED : ▁and r o nov o </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁in ▁some ▁places ▁and ▁usage s , ▁ a ▁billion ▁is ▁ a ▁one ▁followed ▁by ▁nine ▁zero s , ▁or ▁one ▁thousand ▁million ; ▁in ▁other ▁cases , ▁ a ▁billion ▁is ▁ a ▁one ▁followed ▁by ▁twelve ▁zero s , ▁or ▁one ▁million ▁million . ▁in ▁the ▁ u . s . , ▁the ▁common ▁usage ▁of ▁billion ▁refer s ▁to ▁ a ▁one ▁followed ▁by ▁nine ▁zero s ▁( or ▁1,000 ,000,000 ), ▁so ▁that ' s ▁the ▁standard ▁we ▁employ ▁here . ▁query ▁ : ▁how ▁many ▁zero s ▁in ▁billion\n",
      "TRG : ▁nine\n",
      "PREDICTED : ▁nine </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁ if ▁you ▁test ▁after ▁your ▁mis c arri age , ▁you ▁might ▁become ▁confused ▁because ▁of ▁the ▁false ▁positive ▁pregnancy ▁test ▁result . ▁on ▁average , ▁it ▁takes ▁approximately ▁19 ▁days ▁for ▁the ▁ h c g ▁levels ▁in ▁your ▁urine ▁to ▁disappear ▁after ▁you ▁mis car ry . ▁please ▁note ▁that ▁this ▁is ▁just ▁an ▁average ▁length ▁of ▁time . ▁query ▁ : ▁how ▁long ▁with ▁pregnancy ▁test ▁be ▁positive ▁after ▁mis c arri age\n",
      "TRG : ▁19 ▁days\n",
      "PREDICTED : ▁19 ▁days </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁these ▁iron ▁de fic i ency ▁symptoms ▁often ▁go ▁un not ice d ▁because ▁most ▁pregnant ▁women ▁experience ▁fatigue , ▁weakness ▁and ▁di zzi ness ▁at ▁some ▁point a ?? point â ▁whether ▁an e mic ▁or . ▁not ▁query ▁ : ▁pregnancy ▁iron ▁de fic i ency ▁symptoms\n",
      "TRG : ▁fatigue , ▁weakness ▁and ▁di zzi ness\n",
      "PREDICTED : ▁fatigue , ▁weakness ▁and ▁di zzi ness </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁orthopedic ▁one , ▁6 840 ▁perimeter ▁ d r ▁dubl in , ▁ o h ▁ 430 16 ▁(6 14 -7 64 -8 700 ). ▁whether ▁you ▁are ▁looking ▁for ▁information ▁about ▁orthopedic ▁one , ▁searching ▁for ▁ a ▁top ▁physicians ▁ - ▁orthopedic s ▁business ▁near ▁me ▁or ▁within ▁zip ▁code ▁ 430 16 , ▁or ▁just ▁trying ▁to ▁locate ▁ a ▁company ▁that ▁offers ▁physicians ▁ - ▁orthopedic s ▁near ▁dubl in ▁ o h , ▁you ▁will ▁find ▁that ▁ b 2 by ello w page s . com ▁will ▁satisfy ▁your ▁search . ▁query ▁ : ▁orthopedic ▁one ▁dubl in ▁phone ▁number\n",
      "TRG : ▁the ▁phone ▁number ▁for ▁orthopedic ▁one ▁dubl in ▁is ▁6 14 ▁7 64 ▁8 700 .\n",
      "PREDICTED : ▁orthopedic ▁one , ▁6 14 ▁7 64 -8 700 </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁to ll ▁free ▁outlook ▁technical ▁support ▁us a ▁number ▁is ▁1 -8 55 - 90 3-6 16 3. ▁call ▁for ▁outlook ▁tech ▁support . ▁contact ▁to ll ▁free ▁1 ▁8 55 ▁90 3 ▁ 61 63 ▁ microsoft ▁outlook ▁email ▁support ▁services ▁by ▁phone ▁for ▁email ▁support ▁and ▁also ▁tech ▁support . ▁query ▁ : ▁outlook support ▁number\n",
      "TRG : ▁1 -8 55 - 90 3-6 16 3\n",
      "PREDICTED : ▁1 -8 55 - 90 3-6 16 3 </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁ f d a ▁has ▁approved ▁how ▁many ▁novel ▁new ▁drugs ▁so ▁far ▁this ▁year ? ▁for ▁those ▁who ▁like ▁to ▁track ▁the ▁performance ▁of ▁the ▁ f d a , ▁some ▁new ▁metrics ▁have ▁just ▁arrived . ▁last ▁year , ▁the ▁agency ▁approved ▁27 ▁novel ▁new ▁medicines , ▁or ▁new ▁mo le cular ▁entities , ▁in ▁industry ▁par l ance . ▁this ▁ a mounted ▁to ▁7 5% ▁of ▁the ▁36 ▁marketing ▁applications ▁that ▁were ▁received . ▁query ▁ : ▁how ▁many ▁drugs ▁are ▁approved ▁by ▁the ▁ f d a\n",
      "TRG : ▁27 ▁novel ▁new ▁medicines\n",
      "PREDICTED : ▁27 </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁blue ▁pe ter ▁was ▁first ▁ aire d ▁on ▁16 ▁ o c to ber ▁1958 . ▁it ▁had ▁been ▁ commissioned ▁to ▁producer ▁ john ▁hunt er ▁ bla i r ▁by ▁ ow en ▁ re e d , ▁the ▁head ▁of ▁children ' s ▁programmes ▁at ▁the ▁ b b c , ▁as ▁there ▁were ▁no ▁programmes ▁in ▁existence ▁that ▁ca tered ▁for ▁children ▁aged ▁between ▁five ▁and ▁eight . ▁query ▁ : ▁when ▁did ▁pe ter ▁blue ▁first ▁air\n",
      "TRG : ▁blue ▁pe ter ▁was ▁first ▁ aire d ▁on ▁16 ▁ o c to ber ▁1958 .\n",
      "PREDICTED : ▁16 ▁ o c to ber ▁1958 </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁no stal rius ▁begins , ▁commonly ▁ referred ▁to ▁as ▁just ▁no stal rius , ▁is ▁an ▁international ▁vanilla ▁server ▁ based ▁in ▁ europe , ▁fr ance . ▁no stal rius ▁has ▁been ▁developed ▁since ▁2010 ▁by ▁more ▁than ▁16 ▁developers . video s ▁on ▁the ▁official ▁you tube ▁channel ▁that ▁showcase ▁the ▁quality ▁of ▁the ▁server ' s ▁script s ▁have ▁ spawn e d ▁ a ▁large ▁amount ▁of ▁public ▁interest ▁in ▁the ▁server . o stal rius ▁boast s ▁ a ▁very ▁high ▁player ▁base , ▁regularly ▁having ▁over ▁ 5000 ▁players ▁online ▁at ▁peak ▁times , ▁with ▁lowest ▁points ▁of ▁2 500 ▁players ▁on ▁at ▁off - hour s . ▁query ▁ : ▁what ▁is ▁no stal rius\n",
      "TRG : ▁it ▁is ▁an ▁international ▁vanilla ▁server ▁ based ▁in ▁ europe , ▁fr ance .\n",
      "PREDICTED : ▁an ▁international ▁vanilla ▁server ▁ based ▁in ▁ europe , ▁fr ance . </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁one ▁way ▁to ▁figure ▁the ▁start ▁and ▁end ▁times ▁for ▁morning , ▁afternoon , ▁evening ▁and ▁night ▁is ▁to ▁use ▁the ▁meteor ological ▁time , ▁which ▁must ▁agree ▁worldwide ▁for ▁forecast ing . ▁meteor ologists ▁consider ▁morning ▁to ▁be ▁from ▁6 ▁ a . m . ▁to ▁12 ▁ p . m . ▁afternoon ▁last s ▁from ▁12 ▁ p . m . ▁to ▁6 ▁ p . m . ▁evening ▁runs ▁from ▁6 ▁ p . m . ▁to ▁midnight . ▁overnight ▁last s ▁from ▁midnight ▁to ▁6 ▁ a . m . ▁query ▁ : ▁when ▁is ▁it ▁afternoon ▁time\n",
      "TRG : ▁12 ▁ p . m . ▁to ▁6 ▁ p . m .\n",
      "PREDICTED : ▁from ▁12 ▁ p . m . ▁to ▁6 ▁ p . m . </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁ a ▁portrait ▁is ▁ a ▁painting , ▁drawing , ▁or ▁photograph ▁of ▁ a ▁particular ▁person . ▁ luci an ▁fr e u d ▁has ▁been ▁asked ▁to ▁paint ▁ a ▁portrait ▁of ▁the ▁queen . ▁ ... the ▁english ▁portrait ▁paint er ▁august us ▁ john . ▁synonym s : ▁picture , ▁painting , ▁image , ▁photograph ▁more ▁synonym s ▁of ▁portrait . ▁2. ▁count able ▁no un . ▁query ▁ : ▁portrait ▁defined\n",
      "TRG : ▁ a ▁portrait ▁is ▁ a ▁painting , ▁drawing , ▁or ▁photograph ▁of ▁ a ▁particular ▁person .\n",
      "PREDICTED : ▁it ▁is ▁ a ▁painting , ▁drawing , ▁or ▁photographic ▁of ▁ a ▁particular ▁person . </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁driving ▁distance ▁from ▁ j f k ▁to ▁ l g a . ▁the ▁total ▁driving ▁distance ▁from ▁ j f k ▁to ▁ l g a ▁is ▁12 ▁miles ▁or ▁19 ▁kilometers . ▁your ▁trip ▁begins ▁at ▁ john ▁ f . ▁ kenn e d y ▁international ▁airport ▁in ▁new ▁york , ▁new ▁york . ▁it ▁ends ▁at ▁la guard i a ▁airport ▁in ▁new ▁york , ▁new ▁york . ▁query ▁ : ▁how ▁far ▁is ▁ l g a ▁from ▁ j f k\n",
      "TRG : ▁12 ▁miles ▁or ▁19 ▁kilometers\n",
      "PREDICTED : ▁12 ▁miles ▁or ▁19 ▁kilometers </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁originally ▁called ▁the ▁democratic - re public an ▁party ▁the ▁democratic ▁party ▁was ▁founded ▁by ▁ th o mas ▁je ffer son ▁and ▁jam e s ▁mad i son ▁in ▁the ▁17 90 s ▁as ▁ a ▁counter ▁to ▁the ▁federal ist ▁party ▁and ▁ ... ▁promoted ▁states ▁rights . a mes ▁mad i son ▁and ▁ th o mas ▁je ffer son ▁started ▁the ▁democratic - re public an ▁party ▁( but ▁they ▁just ▁called ▁it ▁the ▁republic an ▁party ). ▁they ▁created ▁the ▁republic an ▁party ▁to ▁oppos e ▁the ▁ ... ▁federal ist ▁party . ▁query ▁ : ▁who ▁started ▁the ▁democratic ▁party\n",
      "TRG : ▁ th o mas ▁je ffer son ▁and ▁jam e s ▁mad i son\n",
      "PREDICTED : ▁ th o mas ▁je ffer son ▁and ▁jam e s ▁mad i son </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁best ▁way ▁to ▁build ▁ a ▁fire ▁is ▁to ▁include ▁ tinde r , ▁kind ling ▁and ▁the ▁main ▁fuel . ▁ tinde r ▁is ▁the ▁first ▁thing ▁to ▁catch ▁fire ▁from ▁the ▁match . ▁most ▁people ▁use ▁newspaper , ▁but ▁you ▁can ▁also ▁use ▁dry ▁grass , ▁ bir ch ▁bark ▁or ▁dead , ▁dry ▁leaves . ▁query ▁ : ▁what ▁wood ▁to ▁use ▁as ▁kind ling\n",
      "TRG : ▁ tinde r\n",
      "PREDICTED : ▁ hurst ▁wood </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁number ▁of ▁people ▁who ▁bought ▁fragrance s ▁and ▁cosmetic s ▁almost ▁double d ▁on ▁amazon , ▁says ▁research ▁firm ▁cow en ▁and ▁company . ▁new ▁york ▁( ▁the street ) ▁-- ▁amazon ▁( am z n ) ▁is ▁famous ly ▁known ▁as ▁the ▁everything ▁store , ▁and ▁it ▁certainly ▁runs ▁the ▁ga mut , ▁offering ▁products ▁you ▁have n ' t ▁even ▁heard ▁of . ▁query ▁ : ▁most ▁popular ▁items ▁bought ▁on ▁amazon\n",
      "TRG : ▁fragrance s ▁and ▁cosmetic s\n",
      "PREDICTED : ▁fragrance s ▁and ▁cosmetic s </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁impairment ▁of ▁language , ▁usually ▁caused ▁by ▁left ▁ hem i sphere ▁damage ▁either ▁to ▁bro ca ' s ▁area ▁( i mp air ment ▁speaking ) ▁or ▁wer nick e ' s ▁area ▁( im pai ring ▁understanding , ▁damage ▁in ▁rear ▁par i e tal / tempo ral ▁region ▁in ▁the ▁left ▁ hem i sphere ) ▁query ▁ : ▁which ▁part ▁of ▁the ▁brain ▁is ▁responsible ▁for ▁language ▁comprehension ?\n",
      "TRG : ▁left ▁ hem i sphere\n",
      "PREDICTED : ▁left ▁ hem i sphere </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idxs = random.sample(range(0,len(valid_data.examples)),20)\n",
    "\n",
    "for i in idxs:\n",
    "    src = vars(valid_data.examples[i])['src']\n",
    "    trg = vars(valid_data.examples[i])['trg']\n",
    "    translation = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "    print(f\"SRC : {' '.join(tokenizer.convert_ids_to_tokens(src))}\")\n",
    "    print(f\"TRG : {' '.join(tokenizer.convert_ids_to_tokens(trg))}\")\n",
    "    print(f\"PREDICTED : {' '.join(tokenizer.convert_ids_to_tokens(translation))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
