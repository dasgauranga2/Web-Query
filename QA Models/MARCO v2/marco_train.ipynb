{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from torchtext import data\n",
    "from transformers import T5Tokenizer, T5Model\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/marco_v2_120000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Hello', '▁world', '▁how', '▁are', '▁you', '?']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize('Hello world how are you?')\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8774, 296, 149, 33, 25, 58]\n"
     ]
    }
   ],
   "source": [
    "indexes = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> </s> <pad> <unk>\n"
     ]
    }
   ],
   "source": [
    "init_token = tokenizer.pad_token\n",
    "eos_token = tokenizer.eos_token\n",
    "pad_token = tokenizer.pad_token\n",
    "unk_token = tokenizer.unk_token\n",
    "\n",
    "print(init_token, eos_token, pad_token, unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0 2\n"
     ]
    }
   ],
   "source": [
    "init_token_idx = tokenizer.convert_tokens_to_ids(init_token)\n",
    "eos_token_idx = tokenizer.convert_tokens_to_ids(eos_token)\n",
    "pad_token_idx = tokenizer.convert_tokens_to_ids(pad_token)\n",
    "unk_token_idx = tokenizer.convert_tokens_to_ids(unk_token)\n",
    "\n",
    "print(init_token_idx, eos_token_idx, pad_token_idx, unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "max_input_length = tokenizer.max_model_input_sizes['t5-small']\n",
    "\n",
    "print(max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_cut(sentence):\n",
    "    tokens = tokenizer.tokenize(sentence) \n",
    "    tokens = tokens[:max_input_length-2]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)\n",
    "\n",
    "TRG = data.Field(batch_first = True,\n",
    "                  use_vocab = False,\n",
    "                  tokenize = tokenize_and_cut,\n",
    "                  preprocessing = tokenizer.convert_tokens_to_ids,\n",
    "                  init_token = init_token_idx,\n",
    "                  eos_token = eos_token_idx,\n",
    "                  pad_token = pad_token_idx,\n",
    "                  unk_token = unk_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('src', SRC), ('trg', TRG)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.TabularDataset.splits(\n",
    "                path = '',\n",
    "                train = 'marco2.csv',\n",
    "                format = 'csv',\n",
    "                fields = fields,\n",
    "                skip_header = True)\n",
    "\n",
    "train_data , valid_data = train_data[0].split(split_ratio=0.98,\n",
    "                                             random_state = random.seed(4321))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117600\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data.examples))\n",
    "print(len(valid_data.examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': [2625, 3, 10, 167, 19652, 7, 67, 1224, 44, 306, 7902, 5, 387, 24, 65, 118, 3, 25189, 21, 209, 1962, 19, 1346, 12, 3281, 227, 34, 65, 3, 22964, 5, 3, 99, 150, 119, 1573, 13, 387, 30929, 23, 106, 19, 347, 6, 182, 1312, 5011, 387, 164, 36, 1346, 12, 3281, 3, 99, 34, 65, 118, 16, 8, 5040, 21, 3, 9, 298, 5, 3, 9, 1196, 13, 10607, 33, 347, 45, 8515, 3253, 5, 11417, 3, 10, 149, 307, 12, 13374, 387, 21, 1346, 169], 'trg': [209, 1962]}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[10000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁context', '▁', ':', '▁transition', 'al', '▁period', ':', '▁week', '▁two', '-', 'to', '-', 'four', '.', '▁the', '▁second', '▁week', '▁of', '▁life', '▁brings', '▁great', '▁changes', '▁for', '▁the', '▁puppy', '.', '▁ears', '▁and', '▁eyes', '▁sealed', '▁since', '▁birth', '▁begin', '▁to', '▁open', '▁during', '▁this', '▁period', ',', '▁ears', '▁at', '▁about', '▁two', '▁weeks', '▁and', '▁eye', 'lid', 's', '▁between', '▁', 'ten', '▁to', '▁16', '▁days', '.', '▁this', '▁gives', '▁the', '▁fur', 'ry', '▁babies', '▁', 'a', '▁new', '▁sense', '▁of', '▁their', '▁world', '.', '▁query', '▁', ':', '▁how', '▁old', '▁are', '▁puppies', '▁when', '▁their', '▁ears', '▁open']\n",
      "['▁two', '▁weeks']\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6000])['src'])\n",
    "\n",
    "print(tokens)\n",
    "tokens = tokenizer.convert_ids_to_tokens(vars(train_data.examples[6000])['trg'])\n",
    "\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "\n",
    "train_iterator, valid_iterator = BucketIterator.splits(\n",
    "                                (train_data, valid_data), \n",
    "                                batch_size = BATCH_SIZE,\n",
    "                                device = device,\n",
    "                                sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.t5 = t5 = T5Model.from_pretrained('t5-small')\n",
    "        \n",
    "        self.out = nn.Linear(t5.config.to_dict()['d_model'], t5.config.to_dict()['vocab_size'])\n",
    "                \n",
    "    def forward(self, src, trg):\n",
    "        \n",
    "        embedded = self.t5(input_ids=src, decoder_input_ids=trg)\n",
    "        \n",
    "        output = self.out(embedded[0])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5Model were not initialized from the model checkpoint at t5-small and are newly initialized: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = T5Network().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 76,988,544 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0004\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = pad_token_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 4\n",
    "CLIP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH : 1\tTRAIN LOSS : 1.69\tVALID LOSS : 0.80\tTIME : 1883.62\n",
      "\n",
      "EPOCH : 2\tTRAIN LOSS : 0.68\tVALID LOSS : 0.70\tTIME : 1749.28\n",
      "\n",
      "EPOCH : 3\tTRAIN LOSS : 0.55\tVALID LOSS : 0.70\tTIME : 2249.81\n",
      "\n",
      "EPOCH : 4\tTRAIN LOSS : 0.47\tVALID LOSS : 0.71\tTIME : 3021.30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    \n",
    "    start = time.time()\n",
    "    # TRAIN \n",
    "    #########################################################################\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, batch in enumerate(train_iterator):\n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg[:,:-1])\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "            \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    train_loss = epoch_loss / len(train_iterator)\n",
    "    #########################################################################\n",
    "    \n",
    "    # VALID\n",
    "    #########################################################################\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(valid_iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output = model(src, trg[:,:-1])\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    valid_loss = epoch_loss / len(valid_iterator)\n",
    "    #########################################################################\n",
    "    end = time.time()\n",
    "    \n",
    "    print(f\"EPOCH : {epoch+1}\\tTRAIN LOSS : {train_loss:.2f}\\tVALID LOSS : {valid_loss:.2f}\\tTIME : {end-start:.2f}\\n\")\n",
    "    torch.save(model.state_dict(), f'model_{epoch+1}.pt')\n",
    "    \n",
    "    writer.add_scalar('TRAINING LOSS', train_loss, epoch+1)\n",
    "    writer.add_scalar('VALIDATION LOSS', valid_loss, epoch+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50):\n",
    "    model.eval()\n",
    "\n",
    "    src_indexes = [init_token_idx] + sentence + [eos_token_idx]\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "    trg_indexes = [init_token_idx]\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, trg_tensor)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == eos_token_idx:\n",
    "            break\n",
    "            \n",
    "    return trg_indexes[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC : ▁context ▁ : ▁the ▁average ▁medical ▁transcription ist ▁salary ▁is ▁about ▁$40 k . ▁pay ▁is ▁ based ▁on ▁production , ▁so ▁the ▁more ▁productive ▁ a ▁transcription ist ▁is , ▁the ▁more ▁they ▁earn . ▁an ▁experienced ▁transcription ist , ▁with ▁high ▁production , ▁easily ▁earn s ▁$ 70 k ▁per ▁year . ▁query ▁ : ▁how ▁much ▁can ▁ a ▁transcription ist ▁make\n",
      "TRG : ▁$40 k\n",
      "PREDICTED : ▁$ 70 k ▁per ▁year . </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁africa - the ▁second ▁largest ▁continent ▁in ▁the ▁world ▁is ▁also ▁home ▁to ▁the ▁largest ▁desert ▁in ▁the ▁world - the ▁ s a hara . in ▁fact ▁there ▁are ▁three ▁desert s ▁on ▁the ▁continent - the ▁ s a hara , ▁the ▁ n ami b ▁and ▁the ▁ kal a hari . f ric a - the ▁second ▁largest ▁continent ▁in ▁the ▁world ▁is ▁also ▁home ▁to ▁the ▁largest ▁desert ▁in ▁the ▁world - the ▁ s a hara . ▁query ▁ : ▁what ▁is ▁largest ▁africa n ▁desert\n",
      "TRG : ▁ s a hara ▁desert\n",
      "PREDICTED : ▁ s a hara </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁overall , ▁red ▁onions ▁contain ▁ a ▁higher ▁amount ▁of ▁antioxidant ▁compounds . ▁they ▁are ▁higher ▁in ▁total ▁fla von oids ▁than ▁white ▁onions ▁and ▁yellow ▁onions ▁are ▁considered ▁to ▁be ▁in ▁the ▁middle . ▁red ▁onions ▁contain ▁4 15 ▁to ▁1917 ▁mg ▁of ▁fla von o l s ▁ compared ▁to ▁yellow ▁ones , ▁which ▁only ▁contain ▁ 270 ▁to ▁11 87 ▁mg . ▁query ▁ : ▁why ▁is ▁red ▁onion ▁better ▁than ▁white\n",
      "TRG : ▁they ▁are ▁higher ▁in ▁total ▁fla von oids ▁than ▁white ▁onions .\n",
      "PREDICTED : ▁because ▁of ▁antioxidant ▁compounds . </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁how ▁much ▁does ▁ a ▁ cardi ologist ▁make ? ▁ a ▁ cardi ologist ▁can ▁typically ▁start ▁out ▁earning ▁somewhere ▁between ▁$1 80,000 ▁and ▁$250 ,000. ▁with ▁increasing ▁time ▁in ▁the ▁field , ▁of ▁course , ▁salary ▁increases ; ▁with ▁five ▁or ▁more ▁years ▁of ▁experience , ▁ a ▁physician ▁can ▁expect ▁to ▁earn ▁in ▁the ▁range ▁of ▁$300 , 000 ▁to ▁$400 ,000. ▁query ▁ : ▁how ▁much ▁do ▁record er ▁cardio logists ▁make\n",
      "TRG : ▁ a ▁ cardi ologist ▁can ▁typically ▁start ▁out ▁earning ▁somewhere ▁between ▁$1 80,000 ▁and ▁$250 ,000.\n",
      "PREDICTED : ▁between ▁$1 80,000 ▁and ▁$2 ,000. </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁ideal ▁temperature ▁range ▁for ▁your ▁fridge ▁is ▁35 ▁to ▁38 ▁degrees ▁ fahren heit . ▁bacteria ▁growth ▁starts ▁trip ling ▁around ▁the ▁40 ▁degree ▁mark ▁and ▁things ▁freeze ▁at ▁32 , ▁so ▁we ' re ▁sticking ▁with ▁35 ▁to ▁38 ▁as ▁ a ▁goal . ▁query ▁ : ▁at ▁what ▁temperature ▁should ▁we ▁put ▁the ▁refrigerator\n",
      "TRG : ▁35 ▁to ▁38 ▁degrees ▁ fahren heit\n",
      "PREDICTED : ▁35 ▁to ▁38 ▁degrees ▁ fahren heit </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁party ▁politics , ▁arriving ▁around ▁the ▁same ▁time ▁as ▁american ▁political ▁perspectives , ▁are ▁one ▁such ▁way ▁that ▁perspectives ▁are ▁organized . ▁the ▁primary ▁goal ▁of ▁ a ▁political ▁party ▁is ▁to ▁achieve ▁status ▁and ▁power ▁within ▁the ▁government , ▁thus ▁ implementing ▁legislation ▁and ▁to ▁achieve ▁the ▁desired ▁measures . ▁query ▁ : ▁definition ▁of ▁political ▁perspectives\n",
      "TRG : ▁they ▁are ▁one ▁such ▁way ▁that ▁perspectives ▁are ▁organized .\n",
      "PREDICTED : ▁they ▁are ▁one ▁such ▁way ▁that ▁perspective ▁are ▁organized . </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁shaking ▁legs ▁syndrome , ▁also ▁called ▁the ▁rest less ▁leg ▁syndrome ▁( r l s ) ▁is ▁one ▁of ▁ a ▁number ▁of ▁disorders ▁that ▁can ▁cause ▁the ▁legs ▁to ▁move , ▁ t w itch , ▁or ▁shake ▁un control l ably . ▁query ▁ : ▁what ▁is ▁the ▁cause ▁of ▁shaking ▁legs\n",
      "TRG : ▁legs ▁to ▁move , ▁ t w itch ▁or ▁shake ▁un control l ably .\n",
      "PREDICTED : ▁the ▁legs ▁to ▁move , ▁ t w itch , ▁or ▁shake ▁un control l ably . </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁yes , ▁si r ▁is a a c ▁new t on ▁is ▁best ▁known ▁for ▁his ▁work ▁on ▁gravity . ▁ he ▁also ▁worked ▁on ▁and ▁discovered ▁many ▁other ▁scientific ▁wonder s ▁during ▁his ▁lifetime ▁(16 42 -17 27 ). ▁query ▁ : ▁what ▁significant ▁things ▁was ▁is a a c ▁new t on ▁noted ▁for\n",
      "TRG : ▁his ▁work ▁on ▁gravity .\n",
      "PREDICTED : ▁gravity </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁tous ▁les ▁jours . ▁tous ▁les ▁jours ▁( hang ul : ▁ <unk> ) ▁is ▁ a ▁south ▁ kor e an ▁bakery ▁franchise ▁owned ▁by ▁ c j ▁food ville , ▁ a ▁business ▁group ▁of ▁ c j ▁group . ▁tous ▁les ▁jours ▁means ▁ ' e very day ' ▁in ▁french . ▁tous ▁les ▁jours ▁is ▁ a ▁ a sian - f re nch ▁bakery ▁serving ▁ a ▁selection ▁of ▁bakery ▁goods ▁and ▁beverages . ▁it ▁has ▁more ▁than ▁1 300 ▁locations ▁in ▁ asia ▁and ▁the ▁united ▁states . ▁query ▁ : ▁tous ▁les ▁jours ▁meaning\n",
      "TRG : ▁everyday\n",
      "PREDICTED : ▁ e very day </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁ 0 ▁votes . ▁“ america n ▁buffalo ” ▁or ▁“ plain s ▁buffalo ” ▁are ▁both ▁mis nom er ▁names ▁for ▁the ▁american ▁bis on . ▁currently , ▁ 500,000 ▁exist ▁in ▁the ▁us , ▁but ▁most ▁of ▁these ▁bis on ▁are ▁on ▁ranch e s ▁and ▁farms . ▁only ▁ 20,000 ▁live ▁in ▁the ▁wild ▁in ▁north ▁ america . ▁query ▁ : ▁how ▁many ▁bis on ▁exist ▁today\n",
      "TRG : ▁ 500,000 ▁in ▁us\n",
      "PREDICTED : ▁ 500,000 </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁12 ▁verte bra e ▁in ▁the ▁upper ▁back ▁make ▁up ▁what ▁is ▁known ▁as ▁the ▁ t hora cic ▁spine . ▁they ▁curve ▁out ward ▁and ▁in ward ▁to ▁provide ▁structure ▁for ▁the ▁ rib ▁cage . ▁the ▁bones ▁provide ▁structure ▁and ▁flexibility ▁for ▁the ▁body , ▁while ▁protecting ▁the ▁spinal ▁col u ... ▁read ▁more . ▁query ▁ : ▁is ▁the ▁ t hora cic ▁verte bra e ▁associated ▁with ▁the ▁ rib s\n",
      "TRG : ▁yes , ▁the ▁ t hora cic ▁verte bra e ▁are ▁associated ▁with ▁the ▁ rib s .\n",
      "PREDICTED : ▁yes </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁ a : ▁met form in ▁( brand ▁name : ▁ glu co phag e ) ▁is ▁used ▁to ▁help ▁control ▁blood ▁sugar ▁levels ▁in ▁patients ▁with ▁type ▁2 ▁diabetes . ▁it ▁is ▁available ▁by ▁several ▁manufacturers ▁as ▁ a ▁generic ▁drug . ▁all ▁generic ▁drugs ▁have ▁the ▁same ▁dosage , ▁intended ▁use , ▁effects , ▁side ▁effects , ▁route ▁of ▁administration , ▁and ▁strength ▁as ▁the ▁brand ▁name ▁drug . ▁query ▁ : ▁is ▁met form in ▁generic\n",
      "TRG : ▁yes\n",
      "PREDICTED : ▁yes </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁it ▁now ▁takes ▁an ▁average ▁of ▁eight e en ▁years ▁to ▁become ▁an ▁architect . ▁you ▁need ▁approximately ▁5 ▁years ▁of ▁undergraduate ▁plus ▁3 ▁more ▁years ▁of ▁graduate ▁school . th en ▁you ▁must ▁complete ▁ ... the ▁requirements ▁of ▁the ▁internship ▁development ▁program . ▁query ▁ : ▁how ▁many ▁years ▁does ▁an ▁architect ▁need\n",
      "TRG : ▁you ▁need ▁approximately ▁5 ▁years ▁of ▁undergraduate ▁plus ▁3 ▁more ▁years ▁of ▁graduate ▁school .\n",
      "PREDICTED : ▁eight e en ▁years </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁black ▁death ▁is ▁thought ▁to ▁have ▁originated ▁in ▁the ▁ a rid ▁plain s ▁of ▁central ▁ asia , ▁where ▁it ▁then ▁ travelled ▁along ▁the ▁silk ▁road , ▁reaching ▁crime a ▁by ▁13 43 . ▁from ▁there , ▁it ▁was ▁most ▁likely ▁carried ▁by ▁oriental ▁ rat ▁fle a s ▁living ▁on ▁the ▁black ▁rats ▁that ▁were ▁regular ▁passengers ▁on ▁merchant ▁ships . ▁query ▁ : ▁what ▁city ▁did ▁the ▁black ▁death ▁start ▁in ?\n",
      "TRG : ▁central ▁ asia\n",
      "PREDICTED : ▁ a rid ▁plain s ▁of ▁central ▁ asia </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁ e s o phag us ▁is ▁about ▁9 -10 ▁inches ▁( 25 ▁cent i meter s ) ▁long ▁and ▁less ▁than ▁an ▁inch ▁(2 ▁cent i meter s ) ▁in ▁diameter ▁when ▁relaxed . ▁it ▁is ▁located ▁just ▁posterior ▁to ▁the ▁ trac he a ▁in ▁the ▁neck ▁and ▁ t hora cic ▁regions ▁of ▁the ▁body ▁and ▁passes ▁through ▁the ▁ e s oph age al ▁hi at us ▁of ▁the ▁di a phra g m ▁on ▁its ▁way ▁to ▁the ▁stomach .... ▁anatomy ▁ explorer . ▁query ▁ : ▁how ▁long ▁is ▁the ▁ e s o phag us\n",
      "TRG : ▁about ▁9 -10 ▁inches ▁( 25 ▁cent i meter s ).\n",
      "PREDICTED : ▁9 -10 ▁inches ▁( 25 ▁cent i meter s ) </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁in k ▁master ▁( season ▁2) ▁the ▁second ▁season ▁of ▁the ▁tattoo ▁reality ▁competition ▁in k ▁master ▁premiere d ▁on ▁spike ▁on ▁ o c to ber ▁9 ▁and ▁concluded ▁de c ember ▁18, ▁2012 ▁with ▁ a ▁total ▁of ▁13 ▁episodes . ▁query ▁ : ▁what ▁season ▁are ▁in k ▁master ?\n",
      "TRG : ▁season ▁2\n",
      "PREDICTED : ▁season ▁2 </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁first ▁symptoms ▁of ▁influenza ▁( flu ) ▁virus ▁ b , ▁including ▁fever , ▁chill s , ▁headache , ▁and ▁body ▁ aches , ▁often ▁begin ▁to ▁go ▁away ▁after ▁about ▁2 ▁or ▁3 ▁days . ▁in ▁ s ▁the ▁first ▁symptoms ▁of ▁influenza ▁( flu ) ▁virus ▁ b , ▁including ▁fever , ▁chill s , ▁headache , ▁and ▁body ▁ aches , ▁often ▁begin ▁to ▁go ▁away ▁after ▁about ▁2 ▁or ▁3 ▁days . ▁query ▁ : ▁how ▁long ▁it ▁takes ▁to ▁get ▁over ▁influenza\n",
      "TRG : ▁the ▁first ▁symptoms ▁of ▁influenza ▁often ▁begin ▁to ▁go ▁away ▁after ▁about ▁2 ▁or ▁3 ▁days .\n",
      "PREDICTED : ▁2 ▁or ▁3 ▁days </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁le bron ▁jam e s ▁is ▁almost ▁fully ▁ bald . ▁ n b a . ▁le bron ▁jam e s ▁is ▁almost ▁fully ▁ bald . ▁le bron ▁jam e s ’ ▁hair line ▁has ▁long ▁been ▁rece d ing , ▁so ▁during ▁his ▁trip ▁to ▁the ▁ phil i pp ines , ▁le bron ▁ s have d ▁his ▁head ▁almost ▁completely ▁ bald . ▁query ▁ : ▁is ▁le bron ▁jam e s ▁going ▁ bald\n",
      "TRG : ▁yes\n",
      "PREDICTED : ▁yes </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁the ▁concerns ▁expressed ▁above ▁about ▁the ▁family ' s ▁influence ▁upon ▁ a ▁patient ' s ▁decision ▁to ▁seek ▁physician - a s sisted ▁suicide ▁relate ▁to ▁the ▁informal ▁role ▁of ▁the ▁family ▁in ▁the ▁decision ▁process . he ▁possibility ▁that ▁an ▁individual ▁ possesses ▁and ▁exercises ▁autonomy ▁only ▁within ▁the ▁context ▁of ▁social ▁relationships ▁is ▁discussed , ▁and ▁the ▁family ▁dimensions ▁of ▁assisted ▁suicide ▁are ▁presented . ▁key ▁words : ▁physician - a s sisted , ▁suicide , ▁family , ▁ethics . ▁query ▁ : ▁can ▁the ▁family ▁decide ▁on ▁physician ▁ a sisted ▁suicide\n",
      "TRG : ▁yes\n",
      "PREDICTED : ▁yes </s>\n",
      "\n",
      "SRC : ▁context ▁ : ▁girl ▁ s cou t ▁da is y ▁is ▁the ▁initial ▁level ▁of ▁girl ▁ s cou ting . ▁named ▁for ▁ j ul i ette ▁da is y ▁go r don ▁low , ▁ g s ▁da is ies ▁are ▁in ▁kindergarten ▁and ▁first ▁grade ▁( around ▁ ages ▁5 – 7) . ▁they ▁typically ▁meet ▁in ▁groups ▁of ▁ ten ▁girls ▁with ▁two ▁adult ▁leaders ▁who ▁help ▁the ▁girls ▁plan ▁activities ▁to ▁introduce ▁them ▁to ▁girl ▁ s cou t s . ▁query ▁ : ▁age ▁range ▁for ▁da is y ▁girl ▁ s cou t s\n",
      "TRG : ▁around ▁ ages ▁5 – 7 .\n",
      "PREDICTED : ▁5 – 7 </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idxs = random.sample(range(0,len(valid_data.examples)),20)\n",
    "\n",
    "for i in idxs:\n",
    "    src = vars(valid_data.examples[i])['src']\n",
    "    trg = vars(valid_data.examples[i])['trg']\n",
    "    translation = translate_sentence(src, SRC, TRG, model, device)\n",
    "\n",
    "    print(f\"SRC : {' '.join(tokenizer.convert_ids_to_tokens(src))}\")\n",
    "    print(f\"TRG : {' '.join(tokenizer.convert_ids_to_tokens(trg))}\")\n",
    "    print(f\"PREDICTED : {' '.join(tokenizer.convert_ids_to_tokens(translation))}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
